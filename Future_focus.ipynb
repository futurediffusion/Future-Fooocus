{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB5b3oqbvRXc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/futurediffusion/Future-Fooocus\n",
        "!uv pip install aria2 --no-progress\n",
        "!uv pip install gdown --no-progress"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**Descarga vae**\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import clear_output\n",
        "%cd /content/Future-Fooocus/models/vae\n",
        "vae_model = \"sdxl_vae\" # @param [\"sdxl_vae\",\"sdxl_vae_fix\"]\n",
        "if vae_model == \"sdxl_vae\":\n",
        "    !wget https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\n",
        "elif vae_model == \"sdxl_vae_fix\":\n",
        "    !wget https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\n",
        "clear_output()\n",
        "display(HTML(\"<h1 style='color: cyan;'>Descarga Finalizada</h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T5pCDUQXv-4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**Descarga upscaler**\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import clear_output\n",
        "%cd /content/Future-Fooocus/models/upscale_models\n",
        "modelo = \"anime_sharp\" # @param [\"anime_sharp\",\"ultra_sharp\",\"remacri\",\"personalizado\"]\n",
        "# Descargamos el modelo seleccionado\n",
        "if modelo == \"anime_sharp\":\n",
        "    !wget https://huggingface.co/Kim2091/AnimeSharp/resolve/main/4x-AnimeSharp.pth\n",
        "elif modelo == \"ultra_sharp\":\n",
        "    !wget https://huggingface.co/lokCX/4x-Ultrasharp/resolve/main/4x-UltraSharp.pth\n",
        "elif modelo == \"remacri\":\n",
        "    !wget https://huggingface.co/LyliaEngine/remacri_original/resolve/main/remacri_original.pt\n",
        "elif modelo == \"personalizado\":\n",
        "  personalizado = \"\" # @param {\"type\":\"string\"}\n",
        "!wget {personalizado}\n",
        "clear_output()\n",
        "display(HTML(\"<h1 style='color: cyan;'>Descarga Finalizada</h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EkLwVjKOwR3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**Descarga modelos**\n",
        "from IPython.display import clear_output\n",
        "import requests\n",
        "import os\n",
        "#@markdown Ingresa el link del modelo o modelos a usar recomendado usar de Hugginface deja en blanco el token para evitar errores. <p> Si usas link de civitai ingresa tu token para evitar errores\n",
        "%cd /content/Future-Fooocus/models/checkpoints\n",
        "display(HTML(\"<h1 style='color: yellow;'>Descargando modelo por favor espere...</h1>\"))\n",
        "modelo_url = \"https://huggingface.co/WhiteAiZ/waiSHUFFLENOOB_v20/resolve/main/waiSHUFFLENOOB_v20.safetensors\" # @param {\"type\":\"string\"}\n",
        "nombre_modelo = \"waiSHUFFLENOOB_v20.safetensors\" #@param {\"type\": \"string\"}\n",
        "token_civitai = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# Construye la URL con token solo si este no está vacío\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {modelo_url}?token={token_civitai} -o {nombre_modelo}\n",
        "\n",
        "clear_output()\n",
        "display(HTML(\"<h1 style='color: cyan;'>Descarga Finalizada</h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1AASBml_wEFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**Descargar Loras (solo drive)**\n",
        "#@markdown Descarga tus loras de Drive separa los links por comas `(,)`\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import clear_output\n",
        "!uv pip install gdown -q\n",
        "%cd /content/Future-Fooocus/models/loras\n",
        "lora_urls = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# Separa las URLs por comas\n",
        "urls = [url.strip() for url in lora_urls.split(\",\")]\n",
        "\n",
        "# Descarga cada archivo\n",
        "for url in urls:\n",
        "    !gdown --fuzzy {url}\n",
        "\n",
        "# Muestra mensaje de descarga finalizada\n",
        "display(HTML(\"<h1 style='color: cyan;'>Descarga Finalizada</h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HLMNfNGewJFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**Descargar Loras (Civitai o Hugginface)**\n",
        "#@markdown Ingresa tu token de civitai o dejalo en blanco si es un link de hugginface. <p>\n",
        "#@markdown separa los links por comas `(,)`\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import clear_output\n",
        "%cd /content/Future-Fooocus/models/loras\n",
        "lora_urls = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "token_civitai = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# Separa las URLs por comas\n",
        "urls = [url.strip() for url in lora_urls.split(\",\") if url.strip()] # Ignora URLs vacías\n",
        "\n",
        "# Descarga cada archivo\n",
        "for url in urls:\n",
        "    if token_civitai:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}?token={token_civitai}\n",
        "    else:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url}\n",
        "\n",
        "# Muestra mensaje de descarga finalizada\n",
        "#clear_output()\n",
        "display(HTML(\"<h1 style='color: cyan;'>Descarga Finalizada</h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sqSMVhuxx7Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**Inicia la webui**\n",
        "#@markdown **INICIA FUTURE FOOCUS**\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "# parche para ram\n",
        "# parche para ram\n",
        "if 'installed' not in globals():\n",
        "    !sudo apt-get install -y libjemalloc-dev -q\n",
        "    !gdown --fuzzy https://drive.google.com/file/d/1NFABbKFE19HpK1mqUJpFjFefY_oA9phm/view?usp=sharing -O /content/libjemalloc.so.2\n",
        "    installed = True  # Marcar como instalado\n",
        "else:\n",
        "    print(\"\\033[93mEL parche de ram ya se ha instalado. No es necesario reinstalar.\\033[0m\")\n",
        "    print(\"\\033[93mSaltando...\\033[0m\")\n",
        "\n",
        "%cd /content/Future-Fooocus\n",
        "!uv pip install -r requirements_versions.txt --no-progress\n",
        "!uv pip install xformers==0.0.29.post3 -f https://download.pytorch.org/whl/cu124 --no-progress\n",
        "!python entry_with_update.py --share\n",
        "!python launch.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E9A_FJ4EyPY0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}